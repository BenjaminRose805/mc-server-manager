{
  "id": "snapshot_1771115978416_hqze2mvdm",
  "approvalId": "approval_1771115929762_hxwnjb69b",
  "approvalTitle": "Testing Suite - Requirements Document",
  "version": 2,
  "timestamp": "2026-02-15T00:39:38.416Z",
  "trigger": "approved",
  "status": "pending",
  "content": "# Requirements Document\n\n## Introduction\n\nMC Server Manager currently has zero automated tests — no test files, no test framework, no test scripts, no CI integration. All verification is manual or build-based (`tsc` catches type errors, nothing else). This is explicitly called out as a \"significant gap\" in AGENTS.md and a \"High-risk area\" in the tech steering doc.\n\nAs the project evolves from a single-user server manager into a multi-user community platform with social features (friends, chat, voice, mod sync), the cost of regressions grows exponentially. Critical systems like child process lifecycle management, WebSocket protocol handling, auth flows, and database migrations cannot be reliably verified by hand after every change.\n\nThis spec establishes a comprehensive testing suite using Vitest as the test runner across all packages, with Testing Library for React component testing, supertest for backend HTTP integration tests, and contract tests leveraging existing Zod schemas and shared types. The goal is to create the infrastructure, conventions, and initial test coverage that makes writing tests the path of least resistance for all future development.\n\n## Alignment with Project Direction\n\nTesting infrastructure directly supports the product's reliability objectives. The steering docs identify \"Reliability of server management (zero orphaned processes, clean shutdown)\" as a success metric, and \"No automated tests\" is listed as a known limitation in both the tech steering doc and the root AGENTS.md.\n\nAs the project enters its social features phase (friends, chat, voice, shared servers, mod sync), each new spec adds more integration surface area between packages. A testing suite prevents regressions in existing server management while new features are built, and provides the contract enforcement needed when frontend and backend evolve in parallel.\n\nThis spec is purely additive infrastructure — it changes no application code behavior and has no dependencies on any other spec.\n\n### Dependencies\n\n- **Depends on**: None. This is standalone infrastructure.\n- **Depended on by**: All future specs benefit from testing infrastructure. The design and tasks templates should be updated after this spec to reference `vitest` verification instead of \"manual testing only.\"\n\n---\n\n## Requirements\n\n### REQ-1: Vitest Test Runner Infrastructure\n\n**User Story:** As a developer, I want a test runner configured across all workspace packages, so that I can run tests with a single command from the project root.\n\n#### Acceptance Criteria\n\n1. WHEN a developer runs `npm test` from the project root THEN the system SHALL execute tests in all workspace packages (shared, backend, frontend) and report results with exit code 0 on success, non-zero on failure.\n2. WHEN a developer runs `npm test -w backend` THEN the system SHALL execute only backend tests.\n3. WHEN a developer runs `npm test -w frontend` THEN the system SHALL execute only frontend tests.\n4. WHEN a developer runs `npm test -w shared` THEN the system SHALL execute only shared package tests.\n5. WHEN tests are run in the backend package THEN the test environment SHALL be Node.js (not browser/DOM).\n6. WHEN tests are run in the frontend package THEN the test environment SHALL provide a DOM implementation (happy-dom or jsdom).\n7. WHEN tests are run THEN TypeScript files SHALL be executed directly without a separate compilation step.\n8. WHEN tests are run THEN the `@` path alias in the frontend and `@mc-server-manager/shared` workspace references SHALL resolve correctly.\n\n### REQ-2: Code Coverage Reporting\n\n**User Story:** As a developer, I want to see which lines and branches are covered by tests, so that I can identify gaps and prioritize what to test next.\n\n#### Acceptance Criteria\n\n1. WHEN a developer runs `npm test -- --coverage` THEN the system SHALL generate a coverage report showing line, branch, function, and statement coverage per file.\n2. WHEN a coverage report is generated THEN it SHALL be available in both terminal summary format and an HTML report for detailed browsing.\n3. WHEN coverage is reported THEN it SHALL be scoped to source files only (exclude test files, node_modules, config files, and migration SQL files).\n\n### REQ-3: Shared Package Unit Tests\n\n**User Story:** As a developer, I want the shared utility functions to have comprehensive unit tests, so that changes to version comparison, Java compatibility checks, and other shared logic are automatically verified.\n\n#### Acceptance Criteria\n\n1. WHEN tests are run for the shared package THEN all exported pure functions SHALL have test coverage for their documented behavior, including:\n   - `compareMcVersions` (equal versions, less-than, greater-than, different segment counts)\n   - `getMinJavaForMcVersion` (each version range boundary, unknown versions)\n   - `getJavaMajorVersion` (old format `1.8.0_392`, new format `21.0.1`)\n   - `checkJavaMcCompat` (compatible pair, incompatible pair, null for compatible)\n2. WHEN a pure function's behavior changes THEN at least one test SHALL fail, catching the regression.\n3. WHEN tests exercise `compareMcVersions` THEN they SHALL cover edge cases: equal versions, `1.9` vs `1.10` (numeric not lexicographic), versions with different segment counts (`1.20` vs `1.20.1`).\n\n### REQ-4: Backend HTTP Integration Tests\n\n**User Story:** As a developer, I want to test backend API endpoints against a real Express app with a real database, so that route validation, middleware, service logic, and error handling are verified end-to-end through the HTTP layer.\n\n#### Acceptance Criteria\n\n1. WHEN backend integration tests run THEN they SHALL use the exported Express `app` from `app.ts` with supertest, without starting an HTTP server.\n2. WHEN backend integration tests run THEN they SHALL use a dedicated test SQLite database (not the development database in `data/`), initialized fresh with all migrations for each test suite.\n3. WHEN a test creates data in the database THEN that data SHALL NOT persist between test suites (database is reset or isolated per suite).\n4. WHEN testing authenticated endpoints THEN the test framework SHALL provide a helper to generate valid JWT tokens for test users without going through the full login flow.\n5. WHEN an endpoint receives invalid input THEN the test SHALL verify that Zod validation returns a 400 response with an error message.\n6. WHEN an endpoint is called without authentication (where required) THEN the test SHALL verify a 401 response.\n7. WHEN an endpoint returns a success response THEN the test SHALL verify the response body matches the expected TypeScript interface shape from `@mc-server-manager/shared`.\n8. WHEN backend tests run THEN they SHALL NOT spawn Java child processes, make network requests to Mojang APIs, or perform any I/O beyond the test database.\n\n### REQ-5: Backend Unit Tests for Isolated Logic\n\n**User Story:** As a developer, I want unit tests for backend logic that can be tested without the HTTP layer, so that business rules, data transformations, and error handling are verified in isolation.\n\n#### Acceptance Criteria\n\n1. WHEN unit tests are run THEN the `ConsoleBuffer` ring buffer SHALL be tested for: push behavior, capacity enforcement, chronological ordering of `getLines()`, and empty buffer edge case.\n2. WHEN unit tests are run THEN the `server.properties` parser/writer SHALL be tested for: round-trip parsing (parse then write produces same output), handling of comments, empty values, and special characters.\n3. WHEN unit tests are run THEN custom error classes (`AppError`, `NotFoundError`, `ConflictError`, `ValidationError`, `ForbiddenError`) SHALL be tested for correct `statusCode`, `code`, and `message` properties.\n4. WHEN unit tests are run THEN Zod validation schemas in `routes/validation.ts` SHALL be tested with both valid and invalid inputs.\n\n### REQ-6: Frontend Component Tests\n\n**User Story:** As a developer, I want to test React components in a simulated DOM environment, so that UI rendering, user interactions, and state-driven behavior are verified without a real browser.\n\n#### Acceptance Criteria\n\n1. WHEN component tests run THEN presentational components (e.g., `ServerCard`, `StatusBadge`) SHALL be tested by passing props and asserting on rendered DOM content.\n2. WHEN component tests run THEN they SHALL use Testing Library queries (`getByText`, `getByRole`, etc.) rather than implementation details (class names, internal state).\n3. WHEN a component displays server status THEN the test SHALL verify correct text/styling for each status value (`stopped`, `starting`, `running`, `stopping`, `crashed`).\n4. WHEN a component calls an API function THEN the test SHALL mock the API module rather than making real HTTP requests.\n\n### REQ-7: Frontend Store Tests\n\n**User Story:** As a developer, I want to test Zustand store actions in isolation, so that state management logic is verified without rendering React components.\n\n#### Acceptance Criteria\n\n1. WHEN store tests run THEN Zustand store actions SHALL be testable by calling them directly and asserting on the resulting state.\n2. WHEN a store action calls an API function THEN the API module SHALL be mocked to return controlled responses.\n3. WHEN `appendConsole` is called THEN the test SHALL verify that console lines are capped at the configured maximum (2000 lines).\n4. WHEN `updateServerStatus` is called THEN the test SHALL verify that the correct server's status is updated without affecting other servers.\n\n### REQ-8: Contract Tests Between Frontend and Backend\n\n**User Story:** As a developer, I want automated verification that the frontend API client and backend routes agree on request/response shapes, so that drift between the two packages is caught before runtime.\n\n#### Acceptance Criteria\n\n1. WHEN backend route tests run THEN response bodies SHALL be validated against the shared TypeScript interfaces (e.g., a `GET /api/servers` response conforms to `ServerWithStatus[]`).\n2. WHEN the Zod schema in a backend route is changed THEN a contract test SHALL fail if the corresponding shared type no longer matches.\n3. WHEN a new API endpoint is added THEN the contract test pattern SHALL be documented so developers know to add validation for it.\n\n### REQ-9: Test Utilities and Helpers\n\n**User Story:** As a developer, I want reusable test utilities for common setup tasks (database initialization, auth tokens, mock factories), so that writing new tests is fast and consistent.\n\n#### Acceptance Criteria\n\n1. WHEN writing a backend integration test THEN a helper SHALL exist to: initialize a fresh test database with all migrations applied, and clean it up after the suite.\n2. WHEN writing an authenticated backend test THEN a helper SHALL exist to: create a test user in the database and generate a valid JWT access token for that user.\n3. WHEN writing a frontend component test THEN a helper SHALL exist to: render a component with required providers (router context, auth context) already wrapped.\n4. WHEN writing a frontend test that needs mock server data THEN factory functions SHALL exist to generate valid `Server`, `ServerWithStatus`, and other shared type instances with sensible defaults and overridable fields.\n5. WHEN test utilities are created THEN they SHALL be co-located with their package (`packages/backend/src/test-utils/`, `packages/frontend/src/test-utils/`) and importable via standard paths.\n\n### REQ-10: Test Scripts and Developer Experience\n\n**User Story:** As a developer, I want convenient npm scripts for running tests in different modes, so that testing fits naturally into the development workflow.\n\n#### Acceptance Criteria\n\n1. WHEN a developer runs `npm test` THEN all tests across all packages SHALL run in a single invocation.\n2. WHEN a developer runs `npm run test:watch` THEN tests SHALL re-run automatically when source or test files change.\n3. WHEN a developer runs `npm run test:coverage` THEN a full coverage report SHALL be generated.\n4. WHEN Vitest runs THEN it SHALL display clear, readable output showing which tests passed/failed, with file paths and test names.\n\n---\n\n## Non-Functional Requirements\n\n### Code Architecture and Modularity\n- **Single Responsibility**: Each test file tests one module (one service, one route file, one component, one store)\n- **Modular Design**: Test utilities are isolated and reusable across test files within a package\n- **Transport Separation**: Integration tests go through the HTTP layer; unit tests test services/models directly\n- **Clear Interfaces**: Test helpers export typed functions; mock factories produce correctly-typed objects\n\n### Performance\n- Tests for the full monorepo SHALL complete in under 60 seconds on a modern development machine.\n- Individual package test suites SHALL complete in under 20 seconds each.\n- Test database initialization SHALL be fast enough that per-suite fresh databases do not noticeably slow the test run (better-sqlite3's in-memory mode is acceptable).\n\n### Security\n- Test configuration SHALL NOT contain real credentials, API keys, or sensitive data.\n- Test JWT tokens SHALL use a dedicated test secret that differs from any production/development secret.\n- The test database SHALL be ephemeral (in-memory or temp directory) and SHALL NOT be the development database.\n\n### Reliability\n- Tests SHALL be deterministic — running the same tests multiple times SHALL produce the same results.\n- Tests SHALL NOT depend on execution order (each test/suite is independent).\n- Tests SHALL NOT depend on network access, running Java processes, or external services.\n- Tests SHALL NOT leave side effects (files, running processes, modified global state) after completion.\n\n### Usability\n- Test file naming SHALL follow the pattern `{module-name}.test.ts` or `{component-name}.test.tsx`, co-located with the source file or in a `__tests__/` directory.\n- Error messages from failed tests SHALL clearly indicate what was expected vs. what was received.\n- Adding a new test file SHALL require no configuration changes — Vitest auto-discovers test files by glob pattern.\n",
  "fileStats": {
    "size": 14091,
    "lines": 178,
    "lastModified": "2026-02-15T00:38:43.686Z"
  },
  "comments": []
}